{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set for your computer\n",
    "data_directory = '/'.join(os.getcwd().split(\"/\")[:-1]) + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [173,  74,  20, 101,  83,   1,  38,  39,  72,  50,  21, 164,  57,\n",
    "       169,   8,  63, 102,  34,  80, 192, 139,  88, 112, 116,  61,  46,\n",
    "        51, 165, 135,  89, 108,   7,  25,  15, 125,  93, 130,  71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data\n",
    "orig_data = pd.read_csv(data_directory + 'qaData.csv', parse_dates=['Date'])\n",
    "orig_data['EarningTag2'] = orig_data['EarningTag2'].str.strip()\n",
    "\n",
    "#Add Year and Month, Quarter from Data\n",
    "orig_data['Year'] = orig_data['Date'].dt.year\n",
    "orig_data['Month'] = orig_data['Date'].dt.month\n",
    "orig_data['Quarter'] = orig_data['Month'].apply(lambda x: 1 if x < 4 else 2 if x < 7 else 3 if x < 9 else 4)\n",
    "orig_data['Company'] = orig_data['Company'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['EventType'] = orig_data['EventType'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['Participants'] = orig_data['Participants'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystName'] = orig_data['AnalystName'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['AnalystCompany'] = orig_data['AnalystCompany'].str.title().str.replace(\" \", \"\")\n",
    "orig_data['EarningTag2'] = orig_data['EarningTag2'].str.title().str.replace(\" \", \"\")\n",
    "\n",
    "#Pivot tag\n",
    "pivot_data = (pd.pivot_table(orig_data, index=['Company', 'Participants', 'AnalystName', 'AnalystCompany', 'Month', 'Year', 'Quarter', 'EventType'], columns='EarningTag2', aggfunc='size', fill_value=0)).reset_index()\n",
    "\n",
    "#Melt data\n",
    "pivot_melt_data = pd.melt(pivot_data, id_vars=['Company', 'Participants', 'AnalystName', 'AnalystCompany', 'Month', 'Year', 'Quarter', 'EventType'], var_name='Tag', value_name='NumQ')\n",
    "#One-hot encode\n",
    "pivot_melt_data = pd.concat([pivot_melt_data, \n",
    "                             pd.get_dummies(pivot_melt_data['Company'], prefix='C', prefix_sep=\"_\"),\n",
    "                             pd.get_dummies(pivot_melt_data['Participants'], prefix='P', prefix_sep=\"_\"),\n",
    "                             pd.get_dummies(pivot_melt_data['AnalystName'], prefix='A', prefix_sep=\"_\"),\n",
    "                             pd.get_dummies(pivot_melt_data['AnalystCompany'], prefix='AC', prefix_sep=\"_\"),\n",
    "                             pd.get_dummies(pivot_melt_data['EventType'], prefix='ET', prefix_sep=\"_\"),\n",
    "                             pd.get_dummies(pivot_melt_data['Tag'], prefix='T', prefix_sep=\"_\")], axis=1)\n",
    "pivot_melt_data = pivot_melt_data.reset_index(drop=True)\n",
    "\n",
    "#Analysts Present Data\n",
    "event_analyst_data = orig_data[['Company', 'Participants', 'AnalystName', 'AnalystCompany', 'Month', 'Year', 'Quarter', 'EventType']].drop_duplicates().reset_index(drop=True)\n",
    "event_analyst_data = pd.concat([event_analyst_data, \n",
    "                                pd.get_dummies(event_analyst_data['AnalystName'], prefix='AP', prefix_sep=\"_\"),\n",
    "                                pd.get_dummies(event_analyst_data['AnalystCompany'], prefix='ACP', prefix_sep=\"_\")], axis=1).drop(['AnalystName', 'AnalystCompany'], axis=1)\n",
    "event_analyst_data = event_analyst_data.groupby(['Company', 'Participants', 'Year', 'Month', 'Quarter', 'EventType']).sum().reset_index()\n",
    "\n",
    "all_features_data = pd.merge(pivot_melt_data, event_analyst_data, on=['Company', 'Participants', 'Month', 'Year', 'Quarter', 'EventType'])\n",
    "\n",
    "#Index Data\n",
    "groups = []\n",
    "for i, (name, group) in enumerate(all_features_data.groupby(['Company', 'Participants', 'Month', 'Year', 'Quarter', 'EventType'])):\n",
    "    g2 = group.copy()\n",
    "    g2['EventNumber'] = i\n",
    "    groups.append(g2)\n",
    "    \n",
    "indexed_data = pd.concat(groups)\n",
    "\n",
    "#Merge\n",
    "indexed_data = indexed_data.drop(['Company', 'AnalystName', 'AnalystCompany', 'Participants', 'Tag', 'EventType'], axis=1)\n",
    "indexed_data = indexed_data.reset_index(drop=True)\n",
    "indexed_data['NumQ'] = indexed_data['NumQ'].astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7204057794973152 0\n",
      "0.775150047830823 0\n",
      "0.7154414962877131 0\n",
      "0.7204980209543571 0\n"
     ]
    }
   ],
   "source": [
    "cntModel_data = pd.read_csv(\"data/tagCntModel.csv\")\n",
    "merged_data = pd.merge(indexed_data, cntModel_data, on=['EventNumber']+pd.get_dummies(pivot_melt_data['Tag'], prefix='T', prefix_sep=\"_\").columns.tolist())\n",
    "\n",
    "train, test = merged_data.loc[~merged_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True), \\\n",
    "                merged_data.loc[merged_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = train.drop(['NumQ','EventNumber'], axis=1), train['NumQ'].values\n",
    "X_test, y_test = test.drop(['NumQ', 'EventNumber'], axis=1), test['NumQ'].values\n",
    "\n",
    "scores = np.zeros(50)\n",
    "scores_gbc = np.zeros(50)\n",
    "scores_rf = np.zeros(50)\n",
    "scores_mlp = np.zeros(50)\n",
    "\n",
    "estimator = LogisticRegression().fit(X_train, y_train)\n",
    "preds = estimator.predict_proba(X_test)[:,1]\n",
    "scores[0] = roc_auc_score(y_test, preds)\n",
    "    \n",
    "estimator_gbc = GradientBoostingClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_gbc = estimator_gbc.predict_proba(X_test)[:,1]\n",
    "scores_gbc[0] = roc_auc_score(y_test, preds_gbc)\n",
    "    \n",
    "estimator_rf = RandomForestClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_rf = estimator_rf.predict_proba(X_test)[:,1]\n",
    "scores_rf[0] = roc_auc_score(y_test, preds_rf)\n",
    "\n",
    "estimator_mlp = MLPClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_mlp = estimator_mlp.predict_proba(X_test)[:,1]\n",
    "scores_mlp[0] = roc_auc_score(y_test, preds_mlp)\n",
    "\n",
    "for comp in range(1, 50):\n",
    "    model = NMF(n_components=comp)\n",
    "    X_train_W = model.fit_transform(X_train)\n",
    "    X_test_W = model.transform(X_test)\n",
    "    \n",
    "    estimator = LogisticRegression().fit(X_train_W, y_train)\n",
    "    preds = estimator.predict_proba(X_test_W)[:,1]\n",
    "    scores[comp] = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    estimator_gbc = GradientBoostingClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_gbc = estimator_gbc.predict_proba(X_test_W)[:,1]\n",
    "    scores_gbc[comp] = roc_auc_score(y_test, preds_gbc)\n",
    "    \n",
    "    estimator_rf = RandomForestClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_rf = estimator_rf.predict_proba(X_test_W)[:,1]\n",
    "    scores_rf[comp] = roc_auc_score(y_test, preds_rf)\n",
    "    \n",
    "    estimator_mlp = MLPClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_mlp = estimator_mlp.predict_proba(X_test_W)[:,1]\n",
    "    scores_mlp[comp] = roc_auc_score(y_test, preds_mlp)\n",
    "\n",
    "print(scores.max(), scores.argmax())\n",
    "print(scores_gbc.max(), scores_gbc.argmax())\n",
    "print(scores_rf.max(), scores_rf.argmax())\n",
    "print(scores_mlp.max(), scores_mlp.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit ROC: 0.7221445482362363 0\n",
      "logit ACC 0.8636179684338324 0\n",
      "GBC ROC 0.7743632316569917 0\n",
      "GBC ACC 0.8668555240793201 0\n",
      "RF ROC 0.7293723746163947 0\n",
      "RF ACC 0.8634156212059895 8\n",
      "MLP ROC 0.7187374873772576 0\n",
      "MLP ACC 0.8638203156616754 0\n"
     ]
    }
   ],
   "source": [
    "indexed_data = pd.concat(groups)\n",
    "\n",
    "#Merge\n",
    "indexed_data = indexed_data.drop(['Company', 'AnalystName', 'AnalystCompany', 'Participants', 'Tag', 'EventType'], axis=1)\n",
    "indexed_data = indexed_data.reset_index(drop=True)\n",
    "indexed_data['NumQ'] = indexed_data['NumQ'].astype(bool).astype(int)\n",
    "\n",
    "train, test = indexed_data.loc[~indexed_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True), \\\n",
    "                indexed_data.loc[indexed_data['EventNumber'].isin(test_set)].copy().reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = train.drop(['NumQ','EventNumber'], axis=1), train['NumQ'].values\n",
    "X_test, y_test = test.drop(['NumQ', 'EventNumber'], axis=1), test['NumQ'].values\n",
    "\n",
    "scores = np.zeros(50)\n",
    "acc = np.zeros(50)\n",
    "scores_gbc = np.zeros(50)\n",
    "acc_gbc = np.zeros(50)\n",
    "scores_rf = np.zeros(50)\n",
    "acc_rf = np.zeros(50)\n",
    "scores_mlp = np.zeros(50)\n",
    "acc_mlp = np.zeros(50)\n",
    "\n",
    "estimator = LogisticRegression().fit(X_train, y_train)\n",
    "preds = estimator.predict_proba(X_test)[:,1]\n",
    "scores[0] = roc_auc_score(y_test, preds)\n",
    "acc[0] = accuracy_score(y_test, preds.round())\n",
    "    \n",
    "estimator_gbc = GradientBoostingClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_gbc = estimator_gbc.predict_proba(X_test)[:,1]\n",
    "scores_gbc[0] = roc_auc_score(y_test, preds_gbc)\n",
    "acc_gbc[0] = accuracy_score(y_test, preds_gbc.round())\n",
    "    \n",
    "estimator_rf = RandomForestClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_rf = estimator_rf.predict_proba(X_test)[:,1]\n",
    "scores_rf[0] = roc_auc_score(y_test, preds_rf)\n",
    "acc_rf[0] = accuracy_score(y_test, preds_rf.round())\n",
    "\n",
    "estimator_mlp = MLPClassifier(warm_start=True).fit(X_train, y_train)\n",
    "preds_mlp = estimator_mlp.predict_proba(X_test)[:,1]\n",
    "scores_mlp[0] = roc_auc_score(y_test, preds_mlp)\n",
    "acc_mlp[0] = accuracy_score(y_test, preds_mlp.round())\n",
    "\n",
    "for comp in range(1, 50):\n",
    "    model = NMF(n_components=comp)\n",
    "    X_train_W = model.fit_transform(X_train)\n",
    "    X_test_W = model.transform(X_test)\n",
    "    \n",
    "    estimator = LogisticRegression().fit(X_train_W, y_train)\n",
    "    preds = estimator.predict_proba(X_test_W)[:,1]\n",
    "    scores[comp] = roc_auc_score(y_test, preds)\n",
    "    acc[comp] = accuracy_score(y_test, preds.round())\n",
    "    \n",
    "    estimator_gbc = GradientBoostingClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_gbc = estimator_gbc.predict_proba(X_test_W)[:,1]\n",
    "    scores_gbc[comp] = roc_auc_score(y_test, preds_gbc)\n",
    "    acc_gbc[comp] = accuracy_score(y_test, preds_gbc.round())\n",
    "    \n",
    "    estimator_rf = RandomForestClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_rf = estimator_rf.predict_proba(X_test_W)[:,1]\n",
    "    scores_rf[comp] = roc_auc_score(y_test, preds_rf)\n",
    "    acc_rf[comp] = accuracy_score(y_test, preds_rf.round())\n",
    "    \n",
    "    estimator_mlp = MLPClassifier(warm_start=True).fit(X_train_W, y_train)\n",
    "    preds_mlp = estimator_mlp.predict_proba(X_test_W)[:,1]\n",
    "    scores_mlp[comp] = roc_auc_score(y_test, preds_mlp)\n",
    "    acc_mlp[comp] = accuracy_score(y_test, preds_mlp.round())\n",
    "\n",
    "\n",
    "print('logit ROC:', scores.max(), scores.argmax())\n",
    "print('logit ACC', acc.max(), acc.argmax())\n",
    "print('GBC ROC', scores_gbc.max(), scores_gbc.argmax())\n",
    "print('GBC ACC', acc_gbc.max(), acc_gbc.argmax())\n",
    "print('RF ROC', scores_rf.max(), scores_rf.argmax())\n",
    "print('RF ACC', acc_rf.max(), acc_rf.argmax())\n",
    "print('MLP ROC', scores_mlp.max(), scores_mlp.argmax())\n",
    "print('MLP ACC', acc_mlp.max(), acc_mlp.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9c51a775df67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n\u001b[1;32m    797\u001b[0m                                              \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                              self.learning_rate, k=k)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m# add tree to ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, y_pred, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# compute leaf for each sample in ``X``.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mterminal_regions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# mask all which are not in sample mask.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NMF(n_components=49).fit(X_train)\n",
    "X_train_W = model.transform(X_train)\n",
    "\n",
    "param_grid = {'learning_rate': 10.0**np.arange(-3,0,1),\n",
    "              'min_samples_split': np.arange(2, 10, 2, dtype=int),\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'max_depth': np.arange(1, 5, 1, dtype=int),\n",
    "              'min_samples_leaf': np.arange(1, 10, 1, dtype=int)}\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(warm_start=True), cv=5, param_grid=param_grid, return_train_score=False, scoring=make_scorer(roc_auc_score))\n",
    "grid.fit(X_train_W, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683920174843479"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=49).fit(X_train)\n",
    "X_train_W = model.transform(X_train)\n",
    "X_test_W = model.transform(X_test)\n",
    "\n",
    "estimator = GradientBoostingClassifier().fit(X_train_W, y_train)\n",
    "roc_auc_score(y_test, estimator.predict_proba(X_test_W)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
