{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pickle as pkl\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import textacy\n",
    "from textacy import preprocess_text, Doc, Corpus\n",
    "from textacy.vsm import Vectorizer, GroupVectorizer\n",
    "from textacy.tm import TopicModel\n",
    "en = textacy.load_spacy(\"en_core_web_sm\", disable='parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/qaData.csv', parse_dates=['Date'])\n",
    "ec_data = data.loc[data['EventType']==\"Earnings call\", ['Date', 'Company', 'Participants', 'AnalystName',\t'AnalystCompany', 'EventName', 'EarningTag2', \"Question\"]].copy()\n",
    "ec_data['Quarter'] = ec_data['EventName'].str.split(\"Q\").str[0]\n",
    "ec_data = ec_data.groupby(['Date', \"Company\", \"Participants\", \"EventName\", \"Quarter\"]).apply(lambda x: x.reset_index()).reset_index(drop=True)\n",
    "ec_data.columns = [\"QuestionOrder\", \"Date\", \"Company\", \"Participants\", \"AnalystName\", \"AnalystCompany\", \"EventName\", \"Tag\", \"Question\", \"Quarter\"]\n",
    "ec_data = ec_data[[\"Date\", \"Quarter\", \"Company\", \"Participants\", \"AnalystCompany\", \"AnalystName\", \"QuestionOrder\", \"Tag\", \"Question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = Corpus(lang=en, docs=ec_data.apply(lambda x: Doc(content=' '.join(\n",
    "                                                        [token for token in preprocess_text(text=x['Question'], lowercase=True, no_punct=True, no_contractions=True, no_accents=True, no_currency_symbols=True).split(' ') if len(token)>2]),\n",
    "                                                    lang=en, metadata={'Quarter':x['Quarter'],\n",
    "                                                                       'Company':x['Company'],\n",
    "                                                                       'QuestionOrder':x['QuestionOrder'],\n",
    "                                                                       'AnalystName':x[\"AnalystName\"],\n",
    "                                                                       'Tag':x['Tag']}),axis=1).tolist())\n",
    "tokenized_docs = [list(doc.to_terms_list(ngrams=(1), as_strings=True, normalize='lemma', drop_determiners=True)) for doc in docs]\n",
    "\n",
    "bigram_phraser = Phraser(Phrases(tokenized_docs, min_count=10, threshold=25, delimiter=b' '))\n",
    "bigram_docs = [bigram_phraser[doc] for doc in tokenized_docs] \n",
    "\n",
    "trigram_phraser = Phraser(Phrases(bigram_docs, min_count=5, threshold=10, delimiter=b' '))\n",
    "trigram_docs = [trigram_phraser[doc] for doc in bigram_docs]\n",
    "\n",
    "with open(\"data/tokeizedQuestion.p\", \"wb\") as f:\n",
    "    pkl.dump(trigram_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = [(trigram_phraser[bigram_phraser[list(doc.to_terms_list(ngrams=(1), as_strings=True, normalize='lemma', drop_determiners=True))]], doc.metadata['AnalystName']) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts = [doc.metadata['AnalystName'] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': Timestamp('2015-04-14 00:00:00'),\n",
       " 'Company': 'JPMorgan Chase',\n",
       " 'QuestionOrder': 2,\n",
       " 'AnalystName': 'Glenn Schorr',\n",
       " 'Tag': 'Capital'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst = {}\n",
    "tag = {}\n",
    "quarter = {}\n",
    "\n",
    "for doc in docs:\n",
    "    a = doc.metadata['Analyst']\n",
    "    t = doc.metadata['Tag']\n",
    "    q = doc.metadata['Quarter']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-59b937ffbdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigram_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/textacy/vsm/vectorizers.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, tokenized_docs, grps)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \"\"\"\n\u001b[1;32m    930\u001b[0m         \u001b[0;31m# count terms and fit global weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mgrp_term_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;31m# re-weight values in group-term matrix, as specified in init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0mgrp_term_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reweight_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp_term_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/textacy/vsm/vectorizers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, tokenized_docs, grps)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;31m# sort groups alphabetically (vocabulary_grps modified in-place)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             grp_term_matrix = self._sort_vocab_and_matrix(\n\u001b[0;32m-> 1008\u001b[0;31m                 grp_term_matrix, vocabulary_grps, axis='rows')\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# *now* vocabulary_grps are known and fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_grps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary_grps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/textacy/vsm/vectorizers.py\u001b[0m in \u001b[0;36m_sort_vocab_and_matrix\u001b[0;34m(self, matrix, vocabulary, axis)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \"\"\"\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0msorted_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mnew_idx_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
