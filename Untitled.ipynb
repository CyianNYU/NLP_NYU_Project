{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pickle as pkl\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import textacy\n",
    "from textacy import preprocess_text, Doc, Corpus\n",
    "from textacy.vsm import Vectorizer, GroupVectorizer\n",
    "from textacy.tm import TopicModel\n",
    "en = textacy.load_spacy(\"en_core_web_sm\", disable='parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/qaData.csv', parse_dates=['Date'])\n",
    "ec_data = data.loc[data['EventType']==\"Earnings call\", ['Date', 'Company', 'Participants', 'AnalystName',\t'AnalystCompany', 'EventName', 'EarningTag2', \"Question\"]].copy()\n",
    "ec_data['Quarter'] = ec_data['EventName'].str.split(\"Q\").str[0]\n",
    "ec_data = ec_data.groupby(['Date', \"Company\", \"Participants\", \"EventName\", \"Quarter\"]).apply(lambda x: x.reset_index()).reset_index(drop=True)\n",
    "ec_data.columns = [\"QuestionOrder\", \"Date\", \"Company\", \"Participants\", \"AnalystName\", \"AnalystCompany\", \"EventName\", \"Tag\", \"Question\", \"Quarter\"]\n",
    "ec_data = ec_data[[\"Date\", \"Quarter\", \"Company\", \"Participants\", \"AnalystCompany\", \"AnalystName\", \"QuestionOrder\", \"Tag\", \"Question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = Corpus(lang=en, docs=ec_data.apply(lambda x: Doc(content=' '.join(\n",
    "                                                        [token for token in preprocess_text(text=x['Question'], lowercase=True, no_punct=True, no_contractions=True, no_accents=True, no_currency_symbols=True, no_numbers=True).split(' ') if len(token)>2]),\n",
    "                                                    lang=en, metadata={'Quarter':x['Quarter'],\n",
    "                                                                       'Company':x['Company'],\n",
    "                                                                       'QuestionOrder':x['QuestionOrder'],\n",
    "                                                                       'AnalystName':x[\"AnalystName\"],\n",
    "                                                                       'Tag':x['Tag']}),axis=1).tolist())\n",
    "tokenized_docs = [list(doc.to_terms_list(ngrams=(1), as_strings=True, normalize='lemma', drop_determiners=True)) for doc in docs]\n",
    "\n",
    "bigram_phraser = Phraser(Phrases(tokenized_docs, min_count=10, threshold=25, delimiter=b' '))\n",
    "bigram_docs = [bigram_phraser[doc] for doc in tokenized_docs] \n",
    "\n",
    "trigram_phraser = Phraser(Phrases(bigram_docs, min_count=5, threshold=10, delimiter=b' '))\n",
    "trigram_docs = [trigram_phraser[doc] for doc in bigram_docs]\n",
    "\n",
    "with open(\"data/tokeizedQuestion.p\", \"wb\") as f:\n",
    "    pkl.dump(trigram_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = Vectorizer(tf_type='linear', apply_idf=False, apply_dl=False).fit(trigram_docs)\n",
    "doc_term_matrix = count_vec.transform(trigram_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.sum(doc_term_matrix[ec_data.loc[ec_data['AnalystName']==\"Glenn Schorr\"].index.tolist(),:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 13, 37, 23, 30, 27, 27, 20, 18, 34, 31, 30, 17, 14, 35, 21, 20,\n",
       "       28, 20, 25, 24, 30, 41, 40, 35, 35, 20, 34, 28, 53, 16, 20, 23, 33,\n",
       "       54, 28, 58,  9, 56, 36, 34, 37, 55, 38, 49, 20, 29, 14, 30, 29, 12,\n",
       "       12, 33, 20, 30, 45, 47, 25, 31, 30, 18, 39, 47, 35, 21, 41, 21, 22,\n",
       "       26, 14, 54, 19, 50, 59, 50, 27, 29, 17, 24, 38, 67, 44,  5, 40, 35,\n",
       "       31, 30, 28, 18, 53, 48, 26, 14, 25, 40, 30, 42,  6, 32, 20, 11, 35,\n",
       "       19, 16, 31, 14, 22, 33, 27, 24, 47, 41, 17, 15, 24, 17,  7, 30, 28,\n",
       "       32, 20, 15, 33, 13, 11, 35, 35, 33, 34, 35, 19, 23, 14, 54, 34, 26,\n",
       "       18, 19, 38, 39, 28, 38, 23, 37, 30, 35, 39, 30, 41, 29, 14, 39, 26,\n",
       "       50, 10, 19, 24, 27, 24, 52, 34, 20, 25, 31, 37, 16, 32, 12])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80,  73,  36,  38,  42,  34, 133,  70,  89,  29])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.ravel(aa))[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'130bps'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.id_to_term[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
